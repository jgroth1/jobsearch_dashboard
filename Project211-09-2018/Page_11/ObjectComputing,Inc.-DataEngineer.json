{"job title": "Data Engineer", "company": "Object Computing, Inc.", "city state": "\u2013 Greater St. Louis Area", "rating": "3.5", "job description": "<div>If you're motivated by the challenge of building sophisticated solutions that solve complex business challenges, we want to meet you!</div><br>\n<div>Join our team a Data Engineer and help us develop innovative, enterprise-ready web, software, and mobile applications.</div><br>\n\n<div><strong>Here's what we're looking for:</strong></div>Responsibilities\n\n<ul>\n<li>Assist with data collection and optimization of storage approaches</li><li>Provide support for scalable batch or real-time data processing for discovery and model creation</li><li>Implement scalable APIs for utilizing analytics results (e.g., utilizing models produced)</li><li>Collaborate with data scientists and help them evaluate the computation/data requirements for discovery and the deployed solution</li><li>Design, build, operationalize, and scale some of the largest data pipelines in the world</li><li>Advise on and manage big data infrastructure</li><li>Architect and develop data ingestion pipelines</li><li>Develop proofs of concept with emerging technologies</li><li>Assist with data preparation</li>\n</ul>\n\nRequired Education and Skills\n\n<ul>\n<li>Bachelor's degree in Computer Science or a related technical field</li><li>3 years of experience as a Software Engineer or closely related position</li><li>3 years of of experience with the following:</li><li>Designing, integrating, and optimizing distributed data-processing pipelines</li><li>Utilizing database technologies, including: SQL and No-SQL (e.g., Hadoop, Splunk, Spark, Samza, MySQL, Postgres, MongoDB, Sqlite, Neo4j, Apache Giraph), within a cloud environment</li><li>Writing data processing code in Go, Java, Python, Scala, or other high-performance languages</li><li>Using distributed and fault-tolerant computing and map/reduce processing techniques</li><li>Utilizing Linux/UNIX systems</li><li>Systems-level debugging</li><li>Building REST APIs for analytics services</li><li>Working with or in support of multiple open source communities</li><li>Optimizing critical components in applications for efficiency using C or C++</li><li>Utilizing cloud deployment and virtualization and containerization technologies (e.g, Docker, Ansible, Terraform and Vagrant)</li><li>1 year of experience with the following:</li><li>Machine learning libraries, such as Google CloudML, DataFlow, DataLab, TensorFlow, SciKit Learn, Mahout, and MLib</li><li>Optimizing advanced SQL queries</li><li>Working in an agile environment with SCRUM and PODS</li>\n</ul>\n\n<div>This position is located in our brand-new, state-of-the-art development center in St. Louis, Missouri.</div><div>Relocation assistance may be available.</div>"}