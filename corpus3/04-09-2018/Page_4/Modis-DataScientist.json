{"job title": "Data Scientist", "company": "Modis", "city state": "\u2013 Atlanta, Georgia", "rating": "3.1", "job description": "<p> </p><p> <b> Job Description</b> </p> <p></p> <p> <b> Senior </b> </p> <p> Location: Sandy Springs, GA<br> Job Type: Permanent Direct Hire </p> <p> ***C2C is not eligible for this position and sponsorship is not available. Candidates must be able to go permanent with the client***<br> <br> Top 3 Skills:<br> - MUST have experience implementing Machine Learning <br> - Must have leadership experience<br> - Must have experience with Hadoop</p> <p> <b> Who You Are </b> </p> <p> Curious: You enjoy peeling apart a problem and examining the interrelationships between data that may appear superficially unrelated. </p> <p> Creative: You constantly invent and try new approaches to solving problems, which often have never been applied in such contexts before. </p> <p> Practical: You explore theories with an eye to the real-world application to the business and the potential for improving performance for clients and customers. </p> <p> Focused: You're intent on designing and testing a technique over periods of days and weeks, discovering what is successful and what should be optimized further. Furthermore, you learn from the failure and trying again. </p> <p> Determined: You will have both the challenge and opportunity to help design our analytical backend from the ground-up, and therefore must be comfortable as both a team member and a leader in our data science effort. </p> <p> <b> What You Will be Doing </b> </p> <p> You will build innovative tools to provide our clients with insights on how to improve their business. You will have responsibility for architecting and developing best-in-class analytics that create quantifiable value for our business. You will have responsibility for establishing and sustaining processes and practices that support big data and analytics solutions and applications in an open source environment. You should have a passion for creating solutions and driving innovation with an interest in collaborating with team members. This role demands time spent working independently and as part of a team. You will also focus on specific deadlines defined by the management team. </p> <li> Function as Data Scientist which carries the expectation to enhance an SaaS platform that integrates both relational and non-relational databases at scale with both algorithmic logic and front-end interfaces. </li> <li> Participate in product development with leadership team meetings and communicate with advisors regularly on all matters regarding insights and technology developments. </li> <li> Define the software architecture of the growing data analytics capability and build substantial portions yourself. </li> <li> Requirements </li> <p> Requirements : </p> <li> MS or PhD. Degree in relevant discipline (Math, Statistics, Computer Science, Engineering or Health Sciences) required. </li> <li> 3+ years experience in advanced analytics. </li> <li> 3+ years experience in a data architecture role with deep understanding of architecture principles &amp; best practices. </li> <li> Experience delivering solutions in an Agile environment. </li> <li> Working knowledge of the Hadoop ecosystem (including creating and debugging) </li> <p> Preferred Qualifications: </p> <li> Proficiency in fully architecting and executing complex analytical backends </li> <li> Proficiency with Node.js and SQL; Expert proficiency in one or more programming languages such as Scala/Spark, Python, et al; Expert proficiency in at least one statistical modeling program like R, MATLAB, or SAS </li> <li> Experience in machine learning, artificial intelligence and/or artificial neural networks </li> <li> Proficiency in applying various mathematical and statistical models to include, but not limited to: Discrete Event Simulation, Factor Analysis, Genetic Algorithms, Bayesian Probability Models, Hidden Markov Models and Sensitivity Analysis </li> <li> Ability to setup and maintain database for extremely large datasets using current database technologies (ex. Hadoop) </li> <li> Strong experience in using application programming interfaces (API) </li> <li> Proficient in the big data ecosystem with familiarity with Hadoop, Yarn, Spark, and/or Storm </li> <li> Proficient in at least one big data store, for example: hBase, Cassandra, Hive, etc. </li> <li> Demonstrated technical abilities to engineer products that large datasets, with tools that may include: Cluster computing, Grid Computing, Graphical Processing Unit Computing </li> <li> Commercial Cloud Systems such as Amazon Elastic Cloud Compute EC2 </li> ***C2C is not eligible for this position and sponsorship is not available. Candidates must be able to go permanent with the client***"}