{"job title": "Computational Scientist - Bioinformatics", "company": "The University of Texas Southwestern Medical Center", "city state": "\u2013 Dallas, Texas", "rating": "3.8", "job description": "<strong> Security</strong><br><br>This position is security-sensitive and subject to Texas Education Code 51.215, which authorizes UT Southwestern to obtain criminal history record information<br><br><strong> Salary</strong><br><br>Salary Negotiable<br><br><strong> Experience and Education</strong><br><br>Bachelor's degree in Computer Science or a related field and three (3) years of scientific software development/analysis. Experience with HPC is a strong plus. Master's or PhD preferred. Will consider demonstrated success in publishing computational science results in lieu of experience.<br><br><strong> Job Duties</strong>\n<li> Support faculty and students in adapting computational strategies to the specific features of the HPC infrastructure. Working with a range of systems and technologies such as compute cluster, parallel file systems, high speed interconnects, GPU-based computing and database servers.</li> <li> Develop software and methods to explore, analyze and visualize biological data sets including genomic, imaging and protein structure data.</li> <li> Participate in the design and execution of collaborative research studies in biomedical informatics.</li> <li> Train users on the application and usage of computational systems to help accelerate the pace of scientific discovery.</li> Bioinformatics Core Facility (BICF) at UT Southwestern consists of a team of highly skilled computational biologists, biostatisticians, and scientific programmers who support data analysis projects on campus. We specialize in developing bioinformatics tools and methods for genomics, next-generation sequencing data analysis, and data mining from public data repositories. This work involves the use of the latest computational tools and algorithms available in the field, with a focus on improving existing methods using integrative data analysis methods.\n<br>\n<strong> Other Preferred Experience</strong> <li> A minimum of two years of workflow development experience and previous big data experience with multiple programming languages and technologies</li> <li> Bachelor's degree from an accredited college or university in Computer Science, Computer Engineering, or a related field.</li> <li> Fluency in several programming languages such as Python, Scala, or Java, with the ability to pick up new languages and technologies quickly; Understanding of cloud and distributed systems principles, including load balancing, networks, scaling, in-memory vs. disk; Experience with large-scale, big data methods, such as MapReduce, Hadoop, Spark, Hive, Impala, or Storm is a plus.</li> <li> Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Provide assistance, and resolve problems, using excellent problem-solving skills, verbal/written communication.</li> <li> Good understanding of object-oriented design and design patterns; Familiarity with agile software development practices, testing strategies and solid unit testing skills.</li> <li> Experience with the following: cloud computing and virtualization, persistence technologies both relational and No-SQL and multi-layered distributed applications.</li> <strong> Other Job Responsibilities</strong> <li> Support faculty and staff in optimizing bioinformatics software packages to the specific features of the HPC/cloud infrastructure.</li> <li> Architect, implement and test data processing pipelines (e.g. Hadoop and Spark) and data mining / data science algorithms on a variety of hosted settings, such as Cloud (AWS, Azure, GCP) and internal HPC system (SLURM).</li> <li> Develop containers (Docker/Singularity) to ensure that APIs and processing pipeline can be easily deployed across a variety of hardware and software architectures.</li> <li> Build continuous integration and automated deployment environments.</li> <li> Develop automated reporting for API and system health (process, memory, response time).</li> <li> Translate advanced technical architectures into production systems and contribute to the continual maintenance and testing of processes, APIs and associated user interfaces.</li> <li> Experience in developing database data-structures using MySQL, Postgres, Oracle, MongoDB, etc.</li> <li> Develop software and methods to explore, analyze and visualize biological data sets including genomic, imaging and protein structure data.</li> <li> Train users on the application and usage of computational systems to help accelerate the pace of scientific discovery.</li>\nUTSouthwestern Medical Center is committed to an educational and working environment that provides equal opportunity to all members of the University community. In accordance with federal and state law, the University prohibits unlawful discrimination, including harassment, on the basis of: race; color; religion; national origin; gender, including sexual harassment; age; disability; citizenship; and veteran status. In addition, it is UTSouthwestern policy to prohibit discrimination on the basis of sexual orientation, gender identity, or gender expression."}