{"job title": "Big Data Engineer", "company": "Collabera", "city state": "\u2013 Irving, Texas", "rating": "3.9", "job description": "<p> </p><p> <b> Job Description</b> </p> <p></p> Responsibilities: <br> \u2022Design Hadoop deployment architectures (with features such as high availability, scalability, process isolation, load-balancing, workload scheduling, etc.). <br> \u2022Install, validate, test, and package Hadoop products on Red Hat Linux platforms. <br> \u2022Publish and enforce Hadoop best practices, configuration recommendations, usage design/patterns, and cookbooks to developer community. <br> \u2022Engineer process automation integrations. <br> \u2022Perform security and compliance assessment for all Hadoop products. <br> \u2022Contribute to Application Deployment Framework (requirements gathering, project planning, etc.). <br> \u2022Evaluate capacity for new application on-boarding into a large scale Hadoop cluster. <br> \u2022Provide Hadoop SME and Level-3 technical support for troubleshooting. <br> <br> Qualifications: <br> \u202210+ years overall IT experience. <br> \u20222+ years of experience with Big Data solutions and techniques. <br> \u20222+ years Hadoop application infrastructure engineering and development methodology background. <br> \u2022Experience with Cloudera distribution (CDH) and Cloudera Manager is preferred. <br> \u2022Advanced experience with HDFS, Spark, MapReduce, Hive, HBase, ZooKeeper, Impala, SOLR, KAFKA and Flume. <br> \u2022Experience installing, troubleshooting, and tuning the Hadoop ecosystem. <br> \u2022Experience with multi-tenant platforms taking into account Data Segregation, Resource Management, Access Controls, etc. <br> \u2022Experience with Red Hat Linux, UNIX Shell Scripting, Java, RDBMS, NoSQL, and ETL solutions. <br> \u2022Experience with Kerberos, TLS encryption, SAML, LDAP <br> \u2022Experience with full Hadoop SDLC deployments with associated administration and maintenance functions. <br> \u2022Experience developing Hadoop integrations for data ingestion, data mapping and data processing capabilities. <br> \u2022Experience with designing application solutions that make use of enterprise infrastructure components such as storage, load-balancers, 3-DNS, LAN/WAN, and DNS. <br> \u2022Experience with concepts such as high-availability, redundant system design, disaster recovery and seamless failover. <br> \u2022Overall knowledge of Big Data technology trends, Big Data vendors and products. <br> \u2022Good interpersonal with excellent communication skills - written and spoken English. <br> \u2022Able to interact with client projects in cross-functional teams. <br> \u2022Good team player interested in sharing knowledge and cross-training other team members and shows interest in learning new technologies and products. <br> \u2022Ability to create documents of high quality. Ability to work in a structured environment and follow procedures, processes and policies. <br> \u2022Self-starter who works with minimal supervision. Ability to work in a team of diverse skill sets and geographies. <p> </p><p> <b> Job Requirements</b> </p> <p></p> RDBMS, MS Access, ETL, Disaster Recovery, Management, LDAP, WAN, Compliance, Java, Technical Support, UNIX, Linux, Automation, Architecture, Engineering, Shell, DNS, Training, SDLC, LAN, hadoop"}