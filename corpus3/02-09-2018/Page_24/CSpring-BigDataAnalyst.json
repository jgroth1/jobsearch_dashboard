{"job title": "Big Data Analyst", "company": "CSpring", "city state": "\u2013 Indianapolis, IN", "rating": "3.5", "job description": "CSpring is seeking a Big Data Analyst to join our team in Indianapolis, IN. At CSpring, you truly do make a difference. Be heard, work on challenging assignments, improve your community, and join a growing team that will both challenge you and value your contributions. When you join CSpring, you become part of our Ohana or extended family and our most valuable asset. You are NOT just another \"resource\" as is the case with many other consulting or staffing firms.\n<br><br>\nIf you possess the qualifications listed below, please apply for this position and a member of our recruiting team will contact you directly. Your information will remain confidential and you will never be submitted for a position without your approval.\n<br><br>\nThe ideal candidate will have background in numerous open source data environment/tools such as Hadoop, NiFi, Hortonworks, solr, Spark/Scala, Ambaribe, and others. Must be a quick learner with a desire to understand business processes/IT systems, identify enhancement/automation opportunities and implement solutions someone who is driven by fixing and enhancing. Experience in development and implementation of innovative solutions using both COTS and internally developed software and necessary. The ideal candidate for this position must have experience assessing suboptimal processes and technical solutions, then propose and architect improved solutions to address those areas. The ability to analyze business processes to identify opportunities, solve problems, and implement solutions is the primary focus of this position.\n<br><br>\n<strong>Responsibilities:</strong>\n\n\n<ul>\n<li>Create data flows using NiFi / Hortonworks Data Flow (HDF).</li>\n<li>Pull data from various sources such as shared folders, sftp servers, REST APIs, and parse and process the data into HDFS, Hive, HBase, Weblogic JMS queues, Kafka.</li>\n<li>Sqoop data from various databases into Hadoop.</li>\n<li>Use Hive for ETL processes.</li>\n<li>Use Solr to index documents for searching.</li>\n<li>Create Spark/Scala jobs to process avro files into HBase.</li>\n<li>Use Ambari to manage and monitor Hadoop/Hortonworks HDP clusters.</li>\n</ul>\n\n<strong>Qualifications:</strong>\n\n\n<ul>\n<li>Bachelor's Degree (ie. Computer Science, Math or Engineering etc) or equivalent experience.</li>\n<li>Demonstrated self-starter who can work with little direction in a complex environment.</li>\n<li>Strong consultative and communication skills required for socializing technical concepts and building acceptance of process enhancements and automation.</li>\n<li>Demonstrated ability and willingness to learn new technologies and business concepts and to cross technologies, functions or roles as needed to advance business goals.</li>\n<li>Must have the ability to establish priorities, meet deadlines and concentrate on detailed information. Basic management of small tactical projects may be required.</li>\n</ul>\n\nCSpring offers a comprehensive compensation, training, and benefits package; including Paid Time Off, PPO and HSA Medical Insurance Options, Dental, Vision, STD, LTD, Life Insurance, and IRA Match. For more information about CSpring, please visit our website at<br><br>SDL2017"}