{"job title": "Sr Data Engineer", "company": "Walt Disney Company", "city state": "\u2013 Burbank, California", "rating": "3.8", "job description": "At Disney, were storytellers. We make the impossible, possible. We do this through utilizing and developing cutting-edge technology and pushing the envelope to bring stories to life through our movies, products, interactive games, parks and resorts, and media networks. Now is your chance to join our talented team that delivers unparalleled creative content to audiences around the world.\n<br><br>\nThe enterprise Consumer Data Platform (eCDP) team is part of the Enterprise Tech that is focused on providing large-scale data platform solutions in a shared services model to support enterprise data needs of The Walt Disney Corporation such as Data Analytics &amp; BI, Data Driven Advertising &amp; Marketing, Personalization, etc.\n<br><br>\nAs a Senior Data Engineer you will be designing, building and supporting data pipelines consuming data from multiple different source systems and transforming it into valuable and insightful information. You will have the opportunity to contribute to end-to-end platform design for our cloud architecture and work multi-functionally with operations, data science and the business segments to build batch and real-time data solutions.\n<br><br>\nThe role will be part of a team supporting our Corporate and Segment business lines, including Networks (ABC and ESPN) Studios (Disney, Pixar, Marvel, LucasFilm), Parks &amp; Resorts and Disney Consumer Products &amp; Interactive.\n\n<ul>\n<li>Bachelors degree Computer Science or equivalent</li></ul>\n\n<ul>\n<li>Experience with Apache Kafka, AWS Kinesis, or Google Pub/Sub</li><li>Experience with BI tools like Tableau etc.</li><li>Experience with Scaled Agile Framework</li></ul>\n\n<ul>\n<li>Working experience with at least one relational, analytical or columnar database (5+ years)</li><li>Proficiency in Hadoop ecosystem, experience writing MapReduce, Hive or Spark jobs (3+ years)</li><li>Experience developing data intensive applications in Java or Python (5+ years)</li><li>Experience with data integration tools such as Informatica, Talend, etc. (3+ years)</li><li>Proficiency in SQL, data modeling, and data warehousing</li><li>Excellent problem solving skills</li><li>Exposure to cloud platforms (preferably AWS)</li><li>Working knowledge of Git</li><li>Confident Linux user</li><li>Understanding of Scrum / Agile Methodologies</li></ul>\n\n<ul>\n<li>Design, build, test and support data pipelines across multiple systems and environments</li><li>Create unified enterprise data models for analytics and reporting</li><li>Participate in evaluation of new technologies and cloud services</li><li>As part of Agile development team contribute to architecture, tools and development process improvements</li><li>Work in close collaboration with product management, peer system and software engineering teams to clarify requirements and translate them into robust, scalable, operable solutions that work well within the overall data architecture</li>\n</ul>\n\n<strong>Required Education :</strong> \n\n<ul>\n<li>Bachelors degree Computer Science or equivalent</li>\n</ul>\n\n<strong>Preferred Education :</strong> \n\n<ul>\n<li>Working experience with at least one relational, analytical or columnar database (5+ years)</li><li>Proficiency in Hadoop ecosystem, experience writing MapReduce, Hive or Spark jobs (3+ years)</li><li>Experience developing data intensive applications in Java or Python (5+ years)</li><li>Experience with data integration tools such as Informatica, Talend, etc. (3+ years)</li><li>Proficiency in SQL, data modeling, and data warehousing</li><li>Excellent problem solving skills</li><li>Exposure to cloud platforms (preferably AWS)</li><li>Working knowledge of Git</li><li>Confident Linux user</li><li>Understanding of Scrum / Agile Methodologies</li>\n</ul>\n\n<strong>Company Overview :</strong> \n<br>\nData\n<br>"}